{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autograd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import json\n",
    "import gc\n",
    "import numpy as np\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from utils.dataset import LabeledDataset\n",
    "from utils.model import YoloV3, YoloLoss\n",
    "from utils.postprocess import PostProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config/config.json\", \"r\") as config_file:\n",
    "    main_config = json.load(config_file)\n",
    "\n",
    "try:\n",
    "    model_config = main_config['model']\n",
    "    train_config = main_config['train']\n",
    "    loss_config = main_config['train']['loss']\n",
    "except NameError:\n",
    "    assert False, ('Failed to load config file')\n",
    "except KeyError:\n",
    "    assert False, ('Failed to find key on config file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config['device'] = device\n",
    "model_config['dtype'] = dtype\n",
    "model_config['attrib_count'] = 5 + model_config['class_count']\n",
    "\n",
    "loss_config['device'] = device\n",
    "loss_config['dtype'] = dtype\n",
    "loss_config['attrib_count'] = model_config['attrib_count']\n",
    "\n",
    "train_config['device'] = device\n",
    "train_config['dtype'] = dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_config['use_tensorboard']:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter(log_dir=train_config['tensorboard_dir'])\n",
    "else:\n",
    "    writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_context = { }\n",
    "\n",
    "train_context['dataset'] = LabeledDataset(train_config['train_list'], train_config['train_image'], train_config['train_label'])\n",
    "train_context['dataloader'] = DataLoader(train_context['dataset'], batch_size = train_config['batch_size'], num_workers = 4)\n",
    "train_context['val_dataset'] = LabeledDataset(train_config['val_list'], train_config['train_image'], train_config['train_label'])\n",
    "train_context['val_dataloader'] = DataLoader(train_context['val_dataset'], batch_size = 1, num_workers = 4)\n",
    "\n",
    "train_context['epoch'] = 0\n",
    "train_context['last_checkpoint'] = 0\n",
    "\n",
    "train_context['lr'] = train_config['init_lr']\n",
    "train_context['loss_window'] = []\n",
    "\n",
    "loss_context = { }\n",
    "loss_context['post_conf_threshold'] = loss_config['post_conf_threshold']\n",
    "loss_context['post_iou_threshold'] = loss_config['post_iou_threshold']\n",
    "loss_context['acc_iou_threshold'] = loss_config['acc_iou_threshold']\n",
    "loss_context['acc_start_epoch'] = loss_config['acc_start_epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YoloV3(\n",
       "  (darknet): Darknet53(\n",
       "    (baseline): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (2): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (4): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (route1): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (route2): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (route3): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ResidualLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (body): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): LeakyReLU(negative_slope=0.01)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (yolonet): YoloNet(\n",
       "    (conv3): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (4): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (detect3): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (2): YoloLayer()\n",
       "    )\n",
       "    (conv2_1): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): UpscaleLayer()\n",
       "    )\n",
       "    (conv2_2): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (4): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (detect2): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(512, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (2): YoloLayer()\n",
       "    )\n",
       "    (conv1_1): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): UpscaleLayer()\n",
       "    )\n",
       "    (conv1_2): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (2): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (4): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (detect1): Sequential(\n",
       "      (0): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (2): YoloLayer()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YoloV3(model_config)\n",
    "model.to(model_config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = YoloLoss(loss_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_func = lambda epoch: train_context['lr']\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = train_context['lr'])\n",
    "#train_context['optimizer'] = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lr_func, last_epoch = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer, scheduler, train_context, train_config, loss_context, epochs, tb_writer=None):\n",
    "    \n",
    "    postProcessor = PostProcessor()\n",
    "    \n",
    "    for _ in range(0, epochs):\n",
    "        # training step\n",
    "        model.train()\n",
    "        torch.autograd.set_detect_anomaly(train_config['use_anomaly_detection'])\n",
    "        \n",
    "        print('epoch : ', train_context['epoch'])\n",
    "        print('    time : ', datetime.datetime.now().time())\n",
    "        print('    lr : ', train_context['lr'])\n",
    "        if train_config['use_tensorboard'] and tb_writer is not None:\n",
    "            tb_writer.add_scalar('Step/Learning Rate', train_context['lr'], train_context['epoch'])\n",
    "        \n",
    "        losses = []\n",
    "        obj_losses = []\n",
    "        coord_losses = []\n",
    "        for idx, batches in enumerate(train_context['dataloader']):\n",
    "            image = batches['image'].to(train_config['device'], dtype = train_config['dtype'])\n",
    "            labels = batches['label'].to(train_config['device'], dtype = train_config['dtype'])\n",
    "            label_len = batches['label_len'].to(train_config['device'], dtype = torch.long)\n",
    "            \n",
    "            # forward\n",
    "            out1, out2, out3 = model(image)\n",
    "       \n",
    "            # clear optimizer\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # loss\n",
    "            loss, obj_loss, coord_loss = loss_func(torch.cat((out1, out2, out3), 1), labels, label_len)\n",
    "            losses.append(loss.item() / batches['image'].shape[0])\n",
    "            obj_losses.append(obj_loss.item() / batches['image'].shape[0])\n",
    "            coord_losses.append(coord_loss.item() / batches['image'].shape[0])\n",
    "            \n",
    "            # backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # cleanup\n",
    "            del image, labels, label_len, loss\n",
    "            del out1, out2, out3\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "        # print loss\n",
    "        avg_loss = np.mean(losses) if len(losses) is not 0 else 0\n",
    "        avg_obj_loss = np.mean(obj_losses) if len(obj_losses) is not 0 else 0\n",
    "        avg_coord_loss = np.mean(coord_losses) if len(coord_losses) is not 0 else 0\n",
    "        train_context['loss_window'].append(avg_loss)\n",
    "        print('    loss : ', avg_loss)\n",
    "        print('    obj_loss : ', avg_obj_loss)\n",
    "        print('    coord_loss : ', avg_coord_loss)\n",
    "        if train_config['use_tensorboard'] and tb_writer is not None:\n",
    "            tb_writer.add_scalar('Loss/Training Loss', avg_loss, train_context['epoch'])\n",
    "            tb_writer.add_scalar('Loss/Training Object Loss', avg_obj_loss, train_context['epoch'])\n",
    "            tb_writer.add_scalar('Loss/Training Coord Loss', avg_coord_loss, train_context['epoch'])\n",
    "        \n",
    "\n",
    "        # validate step\n",
    "        if 'val_dataset' in train_context and train_context['val_dataset'] is not None:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                torch.autograd.set_detect_anomaly(False)\n",
    "            \n",
    "                losses = []\n",
    "                obj_losses = []\n",
    "                coord_losses = []\n",
    "                if loss_context['acc_start_epoch'] < train_context['epoch']:\n",
    "                    accs = Counter({})\n",
    "                for idx, batches in enumerate(train_context['val_dataloader']):\n",
    "                \n",
    "                    image = batches['image'].to(train_config['device'], dtype = train_config['dtype'])\n",
    "                    labels = batches['label'].to(train_config['device'], dtype = train_config['dtype'])\n",
    "                    label_len = batches['label_len'].to(train_config['device'], dtype = torch.long)\n",
    "            \n",
    "                    out1, out2, out3 = model(image)\n",
    "                    pred = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "                    loss, obj_loss, coord_loss = loss_func(pred, labels, label_len)\n",
    "                    losses.append(loss.item() / batches['image'].shape[0])\n",
    "                    obj_losses.append(obj_loss.item() / batches['image'].shape[0])\n",
    "                    coord_losses.append(coord_loss.item() / batches['image'].shape[0])\n",
    "                \n",
    "                    if loss_context['acc_start_epoch'] < train_context['epoch']:\n",
    "                        prediction = {}\n",
    "                        prediction['image'] = batches['image'].cpu().permute(0, 2, 3, 1).squeeze(0).numpy()\n",
    "                        prediction['pred'] = pred.cpu().detach().squeeze(0).numpy()\n",
    "                        prediction['label'] = batches['label'].cpu().squeeze(0).numpy()\n",
    "                        prediction['label_len'] = batches['label_len'].cpu().squeeze(0).numpy()\n",
    "                \n",
    "                        bboxes = postProcessor.CUSTOM2(prediction['pred'], loss_context)\n",
    "                        acc = postProcessor.calcAccuracyMap(prediction['label'], prediction['label_len'], bboxes, loss_context)\n",
    "                        accs = accs + Counter(acc)\n",
    "            \n",
    "                    # cleanup\n",
    "                    del image, labels, label_len, loss\n",
    "                    if loss_context['acc_start_epoch'] < train_context['epoch']:\n",
    "                        del prediction, bboxes, acc\n",
    "                    del out1, out2, out3\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "    \n",
    "                # print validation loss\n",
    "                avg_loss = np.mean(losses) if len(losses) is not 0 else 0\n",
    "                avg_obj_loss = np.mean(obj_losses) if len(obj_losses) is not 0 else 0\n",
    "                avg_coord_loss = np.mean(coord_losses) if len(coord_losses) is not 0 else 0\n",
    "                print('    validation loss : ', avg_loss)\n",
    "                if loss_context['acc_start_epoch'] < train_context['epoch']:\n",
    "                    print('    accs : ', accs)\n",
    "                if train_config['use_tensorboard'] and tb_writer is not None:\n",
    "                    tb_writer.add_scalar('Loss/Validation Loss', avg_loss, train_context['epoch'])\n",
    "                    tb_writer.add_scalar('Loss/Validation Object Loss', avg_obj_loss, train_context['epoch'])\n",
    "                    tb_writer.add_scalar('Loss/Validation Coord Loss', avg_coord_loss, train_context['epoch'])\n",
    "                    \n",
    "                    if loss_context['acc_start_epoch'] < train_context['epoch']:\n",
    "                        tp = accs['true positive']\n",
    "                        fn = accs['false negative']\n",
    "                        fp = accs['false positive'] + accs['duplicate']\n",
    "                        accuracy = tp / (tp + fn + fp)\n",
    "                        recall = tp / (tp + fn)\n",
    "                        precision = tp / (tp + fp)\n",
    "                        print('    accuracy : ', accuracy)\n",
    "                        print('    recall : ', recall)\n",
    "                        print('    precision : ', precision)\n",
    "                        tb_writer.add_scalar('Accuracy/Accuracy', accuracy, train_context['epoch'])\n",
    "                        tb_writer.add_scalar('Accuracy/Recall', recall, train_context['epoch'])\n",
    "                        tb_writer.add_scalar('Accuracy/Precision', precision, train_context['epoch'])\n",
    "                        \n",
    "                        if(accuracy >= train_config['target_accuaracy'] and \n",
    "                           recall >= train_config['target_recall'] and \n",
    "                           precision >= train_config['target_precision']):\n",
    "                            # save model\n",
    "                            torch.save(model, train_config['checkpoint_dir'] + 'model_r_' + str(train_context['epoch']) + '.dat')\n",
    "                            \n",
    "                \n",
    "                \n",
    "            \n",
    "        # update learning rate & scheduler\n",
    "        #window_len = len(train_context['loss_window'])\n",
    "        #if (len(train_context['loss_window']) >= train_config['lr_window'] and\n",
    "        #    np.mean(train_context['loss_window']) * train_config['lr_threshold'] <= np.mean(train_context['loss_window'][-2:])):\n",
    "            \n",
    "        #    print('    window size : ', len(train_context['loss_window']))\n",
    "        #    print('    decrease lr to : ', train_context['lr'] * train_config['lr_decay'])\n",
    "                \n",
    "        #    train_context['lr'] = train_context['lr'] * train_config['lr_decay']\n",
    "        #    train_context['loss_window'] = []\n",
    "            \n",
    "        #if len(train_context['loss_window']) > 2 * train_config['lr_window']:\n",
    "        #    train_context['loss_window'] = train_context['loss_window'][(train_config['lr_window'] * 3) // 2:]\n",
    "        if train_context['epoch'] > train_config['lr_decay_start']:\n",
    "            train_context['lr'] = train_context['lr'] * train_config['lr_decay']\n",
    "            train_context['loss_window'] = []\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # update context\n",
    "        train_context['dataset'].shuffle()\n",
    "        train_context['epoch'] += 1\n",
    "        \n",
    "        # save model\n",
    "        if (train_context['epoch'] > train_config['checkpoint_start'] \n",
    "            and train_context['epoch'] % train_config['checkpoint'] is 0):\n",
    "            train_context['last_checkpoint'] = train_config['checkpoint']\n",
    "            torch.save(model, train_config['checkpoint_dir'] + 'model_' + str(train_context['epoch']) + '.dat')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0\n",
      "    time :  09:43:44.611845\n",
      "    lr :  0.1\n",
      "    loss :  3193.4417835987397\n",
      "    obj_loss :  3189.797394467096\n",
      "    coord_loss :  3.6443870777780885\n",
      "    validation loss :  2970.256724231648\n",
      "epoch :  1\n",
      "    time :  09:49:01.324442\n",
      "    lr :  0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ac2a35be9973>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-194b15f2e518>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, loss_func, optimizer, scheduler, train_context, train_config, loss_context, epochs, tb_writer)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;31m# backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;31m# cleanup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, loss_func, optimizer, scheduler, train_context, train_config, loss_context, train_config['epochs'], writer)\n",
    "if writer is not None:\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
