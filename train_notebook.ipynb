{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autograd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import json\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "from utils.dataset import DetectionFolder\n",
    "from utils.model import YoloV3, YoloLoss, PostProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config/config.json\", \"r\") as config_file:\n",
    "    main_config = json.load(config_file)\n",
    "\n",
    "try:\n",
    "    model_config = main_config['model']\n",
    "    loss_config = main_config['loss']\n",
    "    train_config = main_config['train']\n",
    "except NameError:\n",
    "    assert False, ('Failed to load config file')\n",
    "except KeyError:\n",
    "    assert False, ('Failed to find key on config file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config['device'] = device\n",
    "model_config['dtype'] = dtype\n",
    "model_config['attrib_count'] = 5 + model_config['class_count']\n",
    "\n",
    "loss_config['device'] = device\n",
    "loss_config['dtype'] = dtype\n",
    "loss_config['attrib_count'] = model_config['attrib_count']\n",
    "\n",
    "\n",
    "train_config['device'] = device\n",
    "train_config['dtype'] = dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YoloV3(model_config)\n",
    "model.to(model_config['device'])\n",
    "model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = YoloLoss(loss_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_context = { }\n",
    "\n",
    "train_context['dataset'] = DetectionFolder(train_config['train_list'], train_config['train_image'], train_config['train_label'])\n",
    "train_context['dataloader'] = DataLoader(train_context['dataset'], batch_size = train_config['batch_size'], num_workers = 4)\n",
    "\n",
    "train_context['epoch'] = 0\n",
    "train_context['last_checkpoint'] = 0\n",
    "\n",
    "train_context['lr'] = train_config['init_lr']\n",
    "train_context['loss_window'] = []\n",
    "\n",
    "\n",
    "train_context['post_mAp'] = 0.5\n",
    "train_context['post_iou_threshold'] = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_func = lambda epoch: train_context['lr']\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = train_context['lr'])\n",
    "#train_context['optimizer'] = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lr_func, last_epoch = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer, scheduler, train_context, train_config, epochs):\n",
    "    \n",
    "    # set anomaly detection\n",
    "    torch.autograd.set_detect_anomaly(train_config['use_anomaly_detection'])\n",
    "        \n",
    "    # training step\n",
    "    for _ in range(0, epochs):\n",
    "        print('epoch : ', train_context['epoch'])\n",
    "        print('    lr : ', train_context['lr'])\n",
    "        \n",
    "        batch_limit = train_context['dataset'].__len__() \n",
    "        if train_context['epoch'] > train_config['i_drop_start']:\n",
    "            drop_count = ((train_context['epoch'] - train_config['i_drop_start']) * train_config['i_drop_per_epoch'])\n",
    "            batch_limit = max(batch_limit - drop_count, train_config['i_drop_bottom_line'])\n",
    "        batch_limit = batch_limit // train_config['batch_size']\n",
    "        print('    batch_limit : ', batch_limit)\n",
    "        \n",
    "        losses = []\n",
    "        for idx, batches in enumerate(train_context['dataloader']):\n",
    "            if idx > batch_limit:\n",
    "                break\n",
    "                \n",
    "            image = batches['image'].to(train_config['device'], dtype = train_config['dtype'])\n",
    "            labels = batches['label'].to(train_config['device'], dtype = train_config['dtype'])\n",
    "            label_len = batches['label_len'].to(train_config['device'], dtype = torch.long)\n",
    "            \n",
    "            # forward\n",
    "            out1, out2, out3 = model(image)\n",
    "       \n",
    "            # clear optimizer\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # loss\n",
    "            loss = loss_func(torch.cat((out1, out2, out3), 1), labels, label_len)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if idx > 30:\n",
    "                postprocessor = PostProcessor()\n",
    "            \n",
    "                tmp = postprocessor.NMS(torch.cat((out1, out2, out3), 1).cpu(), train_context)\n",
    "                print(tmp)\n",
    "                tmp = postprocessor.GAS(torch.cat((out1, out2, out3), 1).cpu(), train_context)\n",
    "                print(tmp)\n",
    "        \n",
    "            # cleanup\n",
    "            del image, labels, label_len\n",
    "            del out1, out2, out3\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "        # update learning rate & scheduler\n",
    "        avg_loss = np.mean(losses) if len(losses) is not 0 else 0\n",
    "        train_context['loss_window'].append(avg_loss)\n",
    "        print('    loss : ', avg_loss)\n",
    "        \n",
    "        window_len = len(train_context['loss_window'])\n",
    "        if (len(train_context['loss_window']) >= train_config['lr_window'] and\n",
    "            np.mean(train_context['loss_window']) <= np.mean(train_context['loss_window'][-3:])):\n",
    "            \n",
    "            print('    window size : ', len(train_context['loss_window']))\n",
    "            print('    decrease lr to : ', train_context['lr'] * train_config['lr_decay'])\n",
    "                \n",
    "            train_context['lr'] = train_context['lr'] * train_config['lr_decay']\n",
    "            train_context['loss_window'] = []\n",
    "            \n",
    "        if len(train_context['loss_window']) > 3 * train_config['lr_window']:\n",
    "            train_context['loss_window'] = train_context['loss_window'][2 * train_config['lr_window']:]\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "        # update context\n",
    "        train_context['dataset'].shuffle()\n",
    "        train_context['epoch'] += 1\n",
    "        \n",
    "        # save model\n",
    "        if train_context['epoch'] % train_config['checkpoint'] is 0:\n",
    "            train_context['last_checkpoint'] = train_config['checkpoint']\n",
    "            torch.save(model, train_config['checkpoint_dir'] + 'model_' + str(train_context['epoch']) + '.dat')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(model, loss_func, optimizer, scheduler, train_context, train_config, train_config['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
