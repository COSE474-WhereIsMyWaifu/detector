{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autograd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import json\n",
    "import gc\n",
    "import numpy as np\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from utils.dataset import LabeledDataset\n",
    "from utils.model import YoloV3, YoloLoss\n",
    "from utils.postprocess import PostProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config/config.json\", \"r\") as config_file:\n",
    "    main_config = json.load(config_file)\n",
    "\n",
    "try:\n",
    "    model_config = main_config['model']\n",
    "    train_config = main_config['train']\n",
    "    valid_config = main_config['train']['validation']\n",
    "    loss_config = main_config['train']['loss']\n",
    "except NameError:\n",
    "    assert False, ('Failed to load config file')\n",
    "except KeyError:\n",
    "    assert False, ('Failed to find key on config file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config['device'] = device\n",
    "model_config['dtype'] = dtype\n",
    "model_config['attrib_count'] = 5 + model_config['class_count']\n",
    "\n",
    "loss_config['device'] = device\n",
    "loss_config['dtype'] = dtype\n",
    "loss_config['attrib_count'] = model_config['attrib_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_context = { }\n",
    "\n",
    "train_context['device'] = device\n",
    "train_context['dtype'] = dtype\n",
    "\n",
    "train_context['train_set'] = LabeledDataset(train_config['set']['index'], \n",
    "                                          train_config['set']['image_dir'], \n",
    "                                          train_config['set']['label_dir'])\n",
    "train_context['train_loader'] = DataLoader(train_context['train_set'], \n",
    "                                           batch_size = train_config['set']['batch_size'], \n",
    "                                           num_workers = train_config['set']['num_workers'],\n",
    "                                           shuffle = True)\n",
    "\n",
    "train_context['valid_set'] = LabeledDataset(valid_config['set']['index'], \n",
    "                                          valid_config['set']['image_dir'], \n",
    "                                          valid_config['set']['label_dir'])\n",
    "train_context['valid_loader'] = DataLoader(train_context['valid_set'], \n",
    "                                           batch_size = valid_config['set']['batch_size'], \n",
    "                                           num_workers = valid_config['set']['num_workers'],\n",
    "                                           shuffle = False)\n",
    "\n",
    "train_context['epoch'] = 0\n",
    "train_context['last_checkpoint'] = 0\n",
    "train_context['lr'] = train_config['plan']['lr_init']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_x :  tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18.]]]], device='cuda:0')\n",
      "grid_y :  tensor([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "            0.,  0.,  0.,  0.,  0.],\n",
      "          [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "            1.,  1.,  1.,  1.,  1.],\n",
      "          [ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
      "            2.,  2.,  2.,  2.,  2.],\n",
      "          [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
      "            3.,  3.,  3.,  3.,  3.],\n",
      "          [ 4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
      "            4.,  4.,  4.,  4.,  4.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
      "            5.,  5.,  5.,  5.,  5.],\n",
      "          [ 6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
      "            6.,  6.,  6.,  6.,  6.],\n",
      "          [ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,\n",
      "            7.,  7.,  7.,  7.,  7.],\n",
      "          [ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
      "            8.,  8.,  8.,  8.,  8.],\n",
      "          [ 9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,  9.,\n",
      "            9.,  9.,  9.,  9.,  9.],\n",
      "          [10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
      "           10., 10., 10., 10., 10.],\n",
      "          [11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
      "           11., 11., 11., 11., 11.],\n",
      "          [12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12.,\n",
      "           12., 12., 12., 12., 12.],\n",
      "          [13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13., 13.,\n",
      "           13., 13., 13., 13., 13.],\n",
      "          [14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14.,\n",
      "           14., 14., 14., 14., 14.],\n",
      "          [15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
      "           15., 15., 15., 15., 15.],\n",
      "          [16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16.,\n",
      "           16., 16., 16., 16., 16.],\n",
      "          [17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17., 17.,\n",
      "           17., 17., 17., 17., 17.],\n",
      "          [18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18.,\n",
      "           18., 18., 18., 18., 18.]]]], device='cuda:0')\n",
      "grid_x :  tensor([[[[ 0.,  1.,  2.,  ..., 35., 36., 37.],\n",
      "          [ 0.,  1.,  2.,  ..., 35., 36., 37.],\n",
      "          [ 0.,  1.,  2.,  ..., 35., 36., 37.],\n",
      "          ...,\n",
      "          [ 0.,  1.,  2.,  ..., 35., 36., 37.],\n",
      "          [ 0.,  1.,  2.,  ..., 35., 36., 37.],\n",
      "          [ 0.,  1.,  2.,  ..., 35., 36., 37.]]]], device='cuda:0')\n",
      "grid_y :  tensor([[[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "          [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "          ...,\n",
      "          [35., 35., 35.,  ..., 35., 35., 35.],\n",
      "          [36., 36., 36.,  ..., 36., 36., 36.],\n",
      "          [37., 37., 37.,  ..., 37., 37., 37.]]]], device='cuda:0')\n",
      "grid_x :  tensor([[[[ 0.,  1.,  2.,  ..., 73., 74., 75.],\n",
      "          [ 0.,  1.,  2.,  ..., 73., 74., 75.],\n",
      "          [ 0.,  1.,  2.,  ..., 73., 74., 75.],\n",
      "          ...,\n",
      "          [ 0.,  1.,  2.,  ..., 73., 74., 75.],\n",
      "          [ 0.,  1.,  2.,  ..., 73., 74., 75.],\n",
      "          [ 0.,  1.,  2.,  ..., 73., 74., 75.]]]], device='cuda:0')\n",
      "grid_y :  tensor([[[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "          [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "          [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "          ...,\n",
      "          [73., 73., 73.,  ..., 73., 73., 73.],\n",
      "          [74., 74., 74.,  ..., 74., 74., 74.],\n",
      "          [75., 75., 75.,  ..., 75., 75., 75.]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = YoloV3(model_config)\n",
    "model = model.to(model_config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = YoloLoss(loss_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_func = lambda epoch: train_context['lr']\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = train_context['lr'])\n",
    "#train_context['optimizer'] = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lr_func, last_epoch = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer, scheduler, train_context, train_config, epochs):\n",
    "    \n",
    "    postProcessor = PostProcessor()\n",
    "    \n",
    "    if train_config['log']['tb_enable']:\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "        tb_writer = SummaryWriter(log_dir = train_config['log']['tb_dir'])\n",
    "    else:\n",
    "        tb_writer = None\n",
    "    \n",
    "    for _ in range(0, epochs):\n",
    "        # training step\n",
    "        model.train()\n",
    "        torch.autograd.set_detect_anomaly(train_config['enable_anomaly_detection'])\n",
    "        \n",
    "        if train_config['log']['console_enable']:\n",
    "            print('epoch : ', train_context['epoch'])\n",
    "            print('    time : ', datetime.datetime.now().time())\n",
    "            print('    lr : ', train_context['lr'])\n",
    "        if tb_writer is not None:\n",
    "            tb_writer.add_scalar('Step/Learning Rate', train_context['lr'], train_context['epoch'])\n",
    "        \n",
    "        losses = []\n",
    "        obj_losses = []\n",
    "        coord_losses = []\n",
    "        for idx, batches in enumerate(train_context['train_loader']):\n",
    "            image = batches['image'].to(train_context['device'], dtype = train_context['dtype'])\n",
    "            labels = batches['label'].to(train_context['device'], dtype = train_context['dtype'])\n",
    "            label_len = batches['label_len'].to(train_context['device'], dtype = torch.long)\n",
    "            \n",
    "            # forward\n",
    "            out1, out2, out3 = model(image)\n",
    "       \n",
    "            # clear optimizer\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # loss\n",
    "            loss, obj_loss, coord_loss = loss_func(torch.cat((out1, out2, out3), 1), labels, label_len)\n",
    "            losses.append(loss.item())\n",
    "            obj_losses.append(obj_loss.item())\n",
    "            coord_losses.append(coord_loss.item())\n",
    "            \n",
    "            # backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # cleanup\n",
    "            del image, labels, label_len\n",
    "            del out1, out2, out3\n",
    "            del loss, obj_loss, coord_loss\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "        # print loss\n",
    "        train_len = train_context['train_set'].__len__()\n",
    "        avg_loss = np.sum(losses) / train_len if len(losses) is not 0 else 0\n",
    "        avg_obj_loss = np.sum(obj_losses) / train_len if len(obj_losses) is not 0 else 0\n",
    "        avg_coord_loss = np.sum(coord_losses) / train_len if len(coord_losses) is not 0 else 0\n",
    "        \n",
    "        \n",
    "        if train_config['log']['console_enable']:\n",
    "            print('    t_loss : ', avg_loss)\n",
    "            print('    t_obj_loss : ', avg_obj_loss)\n",
    "            print('    t_coord_loss : ', avg_coord_loss)\n",
    "        if tb_writer is not None:\n",
    "            tb_writer.add_scalar('Loss/Training Loss', avg_loss, train_context['epoch'])\n",
    "            tb_writer.add_scalar('Loss/Training Object Loss', avg_obj_loss, train_context['epoch'])\n",
    "            tb_writer.add_scalar('Loss/Training Coord Loss', avg_coord_loss, train_context['epoch'])\n",
    "        \n",
    "\n",
    "        # validate step\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            torch.autograd.set_detect_anomaly(False)\n",
    "            \n",
    "            if train_config['validation']['target']['start_epoch'] <= train_context['epoch']:\n",
    "                enable_accuracy_test = True\n",
    "            else:\n",
    "                enable_accuracy_test = False\n",
    "                \n",
    "            losses = []\n",
    "            obj_losses = []\n",
    "            coord_losses = []\n",
    "            if enable_accuracy_test:\n",
    "                accs = Counter({})\n",
    "                \n",
    "            for idx, batches in enumerate(train_context['valid_loader']):\n",
    "                image = batches['image'].to(train_context['device'], dtype = train_context['dtype'])\n",
    "                labels = batches['label'].to(train_context['device'], dtype = train_context['dtype'])\n",
    "                label_len = batches['label_len'].to(train_context['device'], dtype = torch.long)\n",
    "            \n",
    "                out1, out2, out3 = model(image)\n",
    "                pred = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "                loss, obj_loss, coord_loss = loss_func(pred, labels, label_len)\n",
    "                losses.append(loss.item())\n",
    "                obj_losses.append(obj_loss.item())\n",
    "                coord_losses.append(coord_loss.item())\n",
    "                \n",
    "                if enable_accuracy_test:\n",
    "                    prediction = {}\n",
    "                    prediction['pred'] = pred.cpu().detach().squeeze(0).numpy()\n",
    "                    prediction['label'] = batches['label'].cpu().squeeze(0).numpy()\n",
    "                    prediction['label_len'] = batches['label_len'].cpu().squeeze(0).numpy()\n",
    "                    \n",
    "                    post_config = train_config['validation']['post']\n",
    "                \n",
    "                    bboxes = postProcessor.CUSTOM1(prediction['pred'], post_config)\n",
    "                    acc = postProcessor.calcAccuracyMap(prediction['label'], prediction['label_len'], bboxes, post_config)\n",
    "                    accs = accs + Counter(acc)\n",
    "            \n",
    "                # cleanup\n",
    "                del image, labels, label_len\n",
    "                del out1, out2, out3\n",
    "                del loss, obj_loss, coord_loss\n",
    "                if enable_accuracy_test:\n",
    "                    del prediction, bboxes\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "            # print validation loss\n",
    "            valid_len = train_context['valid_set'].__len__()\n",
    "            avg_loss = np.sum(losses) / valid_len if len(losses) is not 0 else 0\n",
    "            avg_obj_loss = np.sum(obj_losses) / valid_len if len(obj_losses) is not 0 else 0\n",
    "            avg_coord_loss = np.sum(coord_losses) / valid_len if len(coord_losses) is not 0 else 0\n",
    "                \n",
    "            if train_config['log']['console_enable']:\n",
    "                print('    v_loss : ', avg_loss)\n",
    "                print('    v_obj_loss  : ', avg_obj_loss)\n",
    "                print('    v_obj_loss  : ', avg_coord_loss)\n",
    "                \n",
    "            if tb_writer is not None:\n",
    "                tb_writer.add_scalar('Loss/Validation Loss', avg_loss, train_context['epoch'])\n",
    "                tb_writer.add_scalar('Loss/Validation Object Loss', avg_obj_loss, train_context['epoch'])\n",
    "                tb_writer.add_scalar('Loss/Validation Coord Loss', avg_coord_loss, train_context['epoch'])\n",
    "                    \n",
    "            if enable_accuracy_test:\n",
    "                tp = accs['true positive']\n",
    "                fn = accs['false negative']\n",
    "                fp = accs['false positive'] + accs['duplicate']\n",
    "                accuracy = tp / (tp + fn + fp)\n",
    "                recall = tp / (tp + fn)\n",
    "                precision = tp / (tp + fp)\n",
    "                \n",
    "                # print accuracy\n",
    "                if train_config['log']['console_enable']:\n",
    "                    print('    accs : ', accs)\n",
    "                    print('    accuracy : ', accuracy)\n",
    "                    print('    recall : ', recall)\n",
    "                    print('    precision : ', precision)\n",
    "                if tb_writer is not None:\n",
    "                    tb_writer.add_scalar('Accuracy/Accuracy', accuracy, train_context['epoch'])\n",
    "                    tb_writer.add_scalar('Accuracy/Recall', recall, train_context['epoch'])\n",
    "                    tb_writer.add_scalar('Accuracy/Precision', precision, train_context['epoch'])\n",
    "                        \n",
    "                # save model if matching target\n",
    "                if (accuracy >= train_config['validation']['target']['accuaracy'] and \n",
    "                    recall >= train_config['validation']['target']['recall'] and \n",
    "                    precision >= train_config['validation']['target']['precision']):\n",
    "                    \n",
    "                    output_dir = train_config['validation']['target']['save_dir']\n",
    "                    model_name = train_config['validation']['target']['model_prefix'] + str(train_context['epoch'])\n",
    "                    torch.save(model, output_dir + model_name + '.dat')\n",
    "                            \n",
    "        # save model\n",
    "        chkpoint_start = train_config['checkpoint']['start_epoch']\n",
    "        chkpoint_interval = train_config['checkpoint']['interval_epoch']\n",
    "        if (train_context['epoch'] >= chkpoint_start and \n",
    "            (train_context['epoch'] - chkpoint_start) % chkpoint_interval is 0):\n",
    "            \n",
    "            train_context['last_checkpoint'] = train_config['checkpoint']\n",
    "                    \n",
    "            output_dir = train_config['checkpoint']['save_dir']\n",
    "            model_name = train_config['checkpoint']['model_prefix'] + str(train_context['epoch'])\n",
    "            torch.save(model, output_dir + model_name + '.dat')\n",
    "            \n",
    "        # update context\n",
    "        if train_context['epoch'] >= train_config['plan']['lr_decay_start_epoch']:\n",
    "            train_context['lr'] = train_context['lr'] * train_config['plan']['lr_decay_rate']\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "        train_context['epoch'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0\n",
      "    time :  12:27:42.118869\n",
      "    lr :  0.1\n",
      "    t_loss :  3806.3142478249288\n",
      "    t_obj_loss :  3803.412198153409\n",
      "    t_coord_loss :  2.9020511951636183\n",
      "    v_loss :  3635.005122791637\n",
      "    v_obj_loss  :  3631.312946666371\n",
      "    v_obj_loss  :  3.692164013068329\n",
      "epoch :  1\n",
      "    time :  12:28:06.285321\n",
      "    lr :  0.1\n",
      "    t_loss :  3689.1895862926135\n",
      "    t_obj_loss :  3685.9032037908382\n",
      "    t_coord_loss :  3.286361540583047\n",
      "    v_loss :  3555.585429104892\n",
      "    v_obj_loss  :  3551.8167419433594\n",
      "    v_obj_loss  :  3.7686852100516925\n",
      "epoch :  2\n",
      "    time :  12:28:29.376036\n",
      "    lr :  0.1\n",
      "    t_loss :  3687.5922019264913\n",
      "    t_obj_loss :  3684.6482432972302\n",
      "    t_coord_loss :  2.9439396658404307\n",
      "    v_loss :  3569.5102289373226\n",
      "    v_obj_loss  :  3566.1018565784802\n",
      "    v_obj_loss  :  3.4083702260633633\n",
      "epoch :  3\n",
      "    time :  12:28:52.823325\n",
      "    lr :  0.1\n",
      "    t_loss :  3686.104658647017\n",
      "    t_obj_loss :  3683.152843128551\n",
      "    t_coord_loss :  2.9518048083832995\n",
      "    v_loss :  3620.964220913974\n",
      "    v_obj_loss  :  3617.9591175426135\n",
      "    v_obj_loss  :  3.0051035931312735\n",
      "epoch :  4\n",
      "    time :  12:29:16.026065\n",
      "    lr :  0.1\n",
      "    t_loss :  3684.2050836736507\n",
      "    t_obj_loss :  3681.4776888760653\n",
      "    t_coord_loss :  2.7273900454694573\n",
      "    v_loss :  3576.391503073952\n",
      "    v_obj_loss  :  3573.364869551225\n",
      "    v_obj_loss  :  3.0266369160116566\n",
      "epoch :  5\n",
      "    time :  12:29:39.038257\n",
      "    lr :  0.1\n",
      "    t_loss :  3681.9555164683948\n",
      "    t_obj_loss :  3679.267733487216\n",
      "    t_coord_loss :  2.6877867755564777\n",
      "    v_loss :  3590.834587790749\n",
      "    v_obj_loss  :  3588.0092128406873\n",
      "    v_obj_loss  :  2.825377150920262\n",
      "epoch :  6\n",
      "    time :  12:30:01.708372\n",
      "    lr :  0.1\n",
      "    t_loss :  3679.9884421608663\n",
      "    t_obj_loss :  3677.3128495649858\n",
      "    t_coord_loss :  2.6755661317570643\n",
      "    v_loss :  3603.982259576971\n",
      "    v_obj_loss  :  3601.0975473577328\n",
      "    v_obj_loss  :  2.8847136820285497\n",
      "epoch :  7\n",
      "    time :  12:30:25.368240\n",
      "    lr :  0.1\n",
      "    t_loss :  3677.732177734375\n",
      "    t_obj_loss :  3675.0523959073153\n",
      "    t_coord_loss :  2.6797876239500265\n",
      "    v_loss :  3622.275432239879\n",
      "    v_obj_loss  :  3619.5970736416903\n",
      "    v_obj_loss  :  2.6783705664459956\n",
      "epoch :  8\n",
      "    time :  12:30:49.566618\n",
      "    lr :  0.1\n",
      "    t_loss :  3675.246337890625\n",
      "    t_obj_loss :  3672.5637040571733\n",
      "    t_coord_loss :  2.682630082931031\n",
      "    v_loss :  3628.071645563299\n",
      "    v_obj_loss  :  3625.329911665483\n",
      "    v_obj_loss  :  2.741712840104645\n",
      "epoch :  9\n",
      "    time :  12:31:14.143211\n",
      "    lr :  0.1\n",
      "    t_loss :  3672.3254228071733\n",
      "    t_obj_loss :  3669.8017245205965\n",
      "    t_coord_loss :  2.5236958116292953\n",
      "    v_loss :  3585.714132135565\n",
      "    v_obj_loss  :  3582.9314131303267\n",
      "    v_obj_loss  :  2.7827344811098143\n",
      "epoch :  10\n",
      "    time :  12:31:39.052337\n",
      "    lr :  0.1\n",
      "    t_loss :  3669.5913252397017\n",
      "    t_obj_loss :  3666.8438720703125\n",
      "    t_coord_loss :  2.7474821192974392\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3cf37074f11a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'plan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-81b6b70353df>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, loss_func, optimizer, scheduler, train_context, train_config, epochs)\u001b[0m\n\u001b[0;32m    106\u001b[0m                     \u001b[0mpost_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'validation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                     \u001b[0mbboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpostProcessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCUSTOM1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpostProcessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalcAccuracyMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label_len'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                     \u001b[0maccs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Where is My Waifu\\detector\\utils\\postprocess.py\u001b[0m in \u001b[0;36mCUSTOM1\u001b[1;34m(self, prediction, context)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mg1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 \u001b[0miou_match\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miou\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabove_thres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miou_match\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'iou_threshold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                     \u001b[0mnew_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   3116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3117\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[1;32m-> 3118\u001b[1;33m                           out=out, **kwargs)\n\u001b[0m\u001b[0;32m   3119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m     \"\"\"\n\u001b[1;32m--> 591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, loss_func, optimizer, scheduler, train_context, train_config, train_config['plan']['epochs'])\n",
    "if writer is not None:\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
