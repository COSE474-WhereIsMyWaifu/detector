{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import gc \n",
    "\n",
    "import numpy as np \n",
    "from utils.dataset import DetectionFolder\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data_config = { }\n",
    "data_config['train'] = '../data/detect/train.txt'\n",
    "data_config['test'] = '../data/detect/train.txt'\n",
    "data_config['image'] = '../data/detect/images/'\n",
    "data_config['label'] = '../data/detect/labels/'\n",
    "\n",
    "model_config = { }\n",
    "model_config['device'] = device\n",
    "model_config['size'] = (608, 608)\n",
    "model_config['channel'] = 3\n",
    "model_config['dtype'] = torch.float\n",
    "model_config['anchors'] = [(10, 13), (16, 30), (33, 23), (30, 61), (62, 45), (59, 119), (116, 90), (156, 198), (373, 326)]\n",
    "model_config['attribs'] = 5\n",
    "model_config['debug_level'] = 1\n",
    "\n",
    "train_config = { }\n",
    "train_config['coef_noobj'] = 0.2\n",
    "train_config['coef_coord'] = 20 / (608 * 608)\n",
    "train_config['coef_total'] = 2\n",
    "train_config['device'] = device\n",
    "train_config['debug_level'] = 0\n",
    "train_config['iou_threshold'] = 0.75\n",
    "\n",
    "\n",
    "trainset = DetectionFolder(data_config['train'], data_config['image'], data_config['label'])\n",
    "trainloader = DataLoader(trainset, batch_size = 4, num_workers = 4)\n",
    "#testset = DetectionFolder(config['test'], config['image'], config['label'])\n",
    "#testloader = DataLoader(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(trainset.__len__())\n",
    "for indx in range(0, 4):\n",
    "    print(trainset.__getitem__(indx)['label'].shape)\n",
    "    print(trainset.__getitem__(indx))\n",
    "    print(trainset.__getitem__(0)['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, batches in enumerate(trainloader):\n",
    "    print(idx)\n",
    "    print(batches['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = YoloV3(model_config)\n",
    "model.to(model_config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss():\n",
    "    def __init__(self, config):\n",
    "        self.device = config['device']\n",
    "        \n",
    "        self.coef_noobj = torch.tensor(config['coef_noobj']).to(self.device)\n",
    "        self.coef_coord = torch.tensor(config['coef_coord']).to(self.device)\n",
    "        self.coef_total = torch.tensor(config['coef_total']).to(self.device)\n",
    "        self.debug_level = config['debug_level']\n",
    "        self.iou_threshold = config['iou_threshold']\n",
    "        \n",
    "        self.iou_epsilon = torch.tensor(1e-9).to(self.device)\n",
    "        \n",
    "    def __call__(self, pred, label, label_len):\n",
    "        if self.debug_level >= 2:\n",
    "            print('pred shape: ', pred.shape)\n",
    "            print('label shape: ', label.shape)\n",
    "            print('label_len: ', label_len)\n",
    "        # pred = B * P * Attrib\n",
    "        # label = B * 15 * Attrib\n",
    "        \n",
    "        pred = F.relu(pred)\n",
    "        label = F.relu(label)\n",
    "        \n",
    "        if self.debug_level >= 3:\n",
    "            print('pred : ', pred)\n",
    "            print('label_len : ', label_len)\n",
    "            print('label : ', label)\n",
    "            \n",
    "        # iou = B * P * 15\n",
    "        # obj_mask = B * P * 15\n",
    "        iou = self.batch_iou(pred, label)\n",
    "        obj_mask = self.batch_obj_mask(iou, label_len)\n",
    "        if self.debug_level >= 3:\n",
    "            print('iou : ', iou)\n",
    "        if self.debug_level >= 2:\n",
    "            print('obj_mask.shape : ', obj_mask.shape)\n",
    "        \n",
    "        # objectness loss = B * P * 15\n",
    "        obj_loss = self.batch_obj_loss(obj_mask, pred, label_len)\n",
    "        if self.debug_level >= 2:\n",
    "            print('obj_loss : ', obj_loss)\n",
    "        \n",
    "        # coord loss = B * P * 15\n",
    "        coord_loss = self.batch_coord_loss(obj_mask, pred, label)\n",
    "        if self.debug_level >= 2:\n",
    "            print('coord_loss : ', coord_loss)\n",
    "        \n",
    "        # classfication loss = B * P * 15\n",
    "        #class_loss = obj_mask * self.batch_class_loss(pred, label)\n",
    "        \n",
    "        total_loss = torch.sum(obj_loss + coord_loss)\n",
    "        if self.debug_level >= 1:\n",
    "            print('total_loss : ', total_loss)\n",
    "        \n",
    "        return total_loss\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        num_batch = pred.shape[0]\n",
    "        \n",
    "        total_loss = torch.tensor([0.0], device=self.device)\n",
    "        \n",
    "        for batch_idx in range(num_batch):\n",
    "            \n",
    "            iou = self.calc_iou(pred[batch_idx], label[batch_idx])\n",
    "            responsibile = self.calc_responsibile(iou)\n",
    "            \n",
    "            # coord loss\n",
    "            coord_loss = self.calc_coord_loss(pred[batch_idx], label[batch_idx], responsibile)\n",
    "            mean_coord_loss = torch.mean(coord_loss) * self.coef_coord\n",
    "            \n",
    "            if self.debug_level >= 2:\n",
    "                print('mean_coord_loss', mean_coord_loss)\n",
    "            total_loss += mean_coord_loss\n",
    "            \n",
    "            # conf loss\n",
    "            conf_loss = self.calc_confidence_loss(pred[batch_idx], iou, responsibile)\n",
    "            mean_conf_loss = torch.mean(conf_loss)\n",
    "            if self.debug_level >= 2:\n",
    "                print('mean_coord_loss', mean_coord_loss)\n",
    "            total_loss += mean_conf_loss\n",
    "            \n",
    "            \n",
    "            if self.debug_level >= 2:\n",
    "                print('iou : ', iou)\n",
    "                print('iou type: ', iou.type())\n",
    "                print('iou shape: ', iou.shape)\n",
    "                print('responsibile : ', responsibile)\n",
    "                print('coord_loss : ', coord_loss)\n",
    "                print('coord_loss type : ', coord_loss.type())\n",
    "                print('conf_loss : ', conf_loss)\n",
    "                print('conf_loss type : ', conf_loss.type())\n",
    "        if self.debug_level >= 1:\n",
    "            print('loss : ', total_loss / num_batch * self.coef_total)\n",
    "        \n",
    "        return total_loss / num_batch * self.coef_total\n",
    "    \n",
    "    ### from https://github.com/westerndigitalcorporation/YOLOv3-in-PyTorch/blob/release/src/model.py\n",
    "    def batch_iou(self, pred, label):\n",
    "        x1 = label[..., 0]\n",
    "        y1 = label[..., 1]\n",
    "        w1 = label[..., 2]\n",
    "        h1 = label[..., 3]\n",
    "\n",
    "        x2 = pred[..., 0]\n",
    "        y2 = pred[..., 1]\n",
    "        w2 = pred[..., 2]\n",
    "        h2 = pred[..., 3]\n",
    "\n",
    "        area1 = w1 * h1\n",
    "        area2 = w2 * h2\n",
    "\n",
    "        x1 = x1 - w1 / 2\n",
    "        y1 = y1 - h1 / 2\n",
    "        x2 = x2 - w2 / 2\n",
    "        y2 = y2 - h2 / 2\n",
    "        right1 = (x1 + w1).unsqueeze(2)\n",
    "        right2 = (x2 + w2).unsqueeze(1)\n",
    "        top1 = (y1 + h1).unsqueeze(2)\n",
    "        top2 = (y2 + h2).unsqueeze(1)\n",
    "        left1 = x1.unsqueeze(2)\n",
    "        left2 = x2.unsqueeze(1)\n",
    "        bottom1 = y1.unsqueeze(2)\n",
    "        bottom2 = y2.unsqueeze(1)\n",
    "        \n",
    "        \n",
    "        w_intersect = (torch.min(right1, right2) - torch.max(left1, left2)).clamp(min=0)\n",
    "        h_intersect = (torch.min(top1, top2) - torch.max(bottom1, bottom2)).clamp(min=0)\n",
    "        area_intersect = h_intersect * w_intersect\n",
    "\n",
    "        iou_ = area_intersect / (area1.unsqueeze(2) + area2.unsqueeze(1) - area_intersect + self.iou_epsilon)\n",
    "\n",
    "        return iou_\n",
    "        \n",
    "    def batch_obj_mask(self, iou, label_len):\n",
    "        max_iou, max_iou_indx = torch.max(iou, 2)\n",
    "        if self.debug_level >= 2:\n",
    "            print('max_iou ', max_iou)\n",
    "        \n",
    "        obj_mask = torch.where(iou > max_iou.unsqueeze(2) * self.iou_threshold, \n",
    "                               torch.ones_like(iou), torch.zeros_like(iou))\n",
    "        \n",
    "        if self.debug_level >= 2:\n",
    "            print('nonzero ', torch.nonzero(obj_mask).shape[0])\n",
    "        \n",
    "        return obj_mask\n",
    "    \n",
    "    def batch_obj_loss(self, obj_mask, pred, label_len):\n",
    "        coef_mask = torch.where(obj_mask == 1, \n",
    "                                torch.ones_like(obj_mask), torch.ones_like(obj_mask) * self.coef_noobj)\n",
    "        \n",
    "        conf = torch.transpose(pred[..., 4].clone().repeat(obj_mask.shape[1], 1, 1), 0, 1)\n",
    "        \n",
    "        obj_loss_all = coef_mask * F.mse_loss(obj_mask, conf, reduction='none')\n",
    "        \n",
    "        obj_loss = torch.tensor(0.0, device = self.device)\n",
    "        for indx in range(0, label_len.shape[0]):\n",
    "            obj_loss += torch.sum(obj_loss_all[indx][0:label_len[indx]])\n",
    "        \n",
    "        if self.debug_level >= 2:\n",
    "            print('max conf : ', torch.max(obj_loss_all))\n",
    "        if self.debug_level >= 4:\n",
    "            print('obj_loss.shape', obj_loss.shape)\n",
    "        \n",
    "        return obj_loss\n",
    "        \n",
    "    def batch_coord_loss(self, obj_mask, pred, label):\n",
    "        x1 = label[..., 0].repeat(pred.shape[1], 1, 1).permute(1, 2, 0)\n",
    "        y1 = label[..., 1].repeat(pred.shape[1], 1, 1).permute(1, 2, 0)\n",
    "        w1 = label[..., 2].repeat(pred.shape[1], 1, 1).permute(1, 2, 0)\n",
    "        h1 = label[..., 3].repeat(pred.shape[1], 1, 1).permute(1, 2, 0)\n",
    "        \n",
    "        x2 = torch.transpose(pred[..., 0].repeat(label.shape[1], 1, 1), 0, 1)\n",
    "        y2 = torch.transpose(pred[..., 1].repeat(label.shape[1], 1, 1), 0, 1)\n",
    "        w2 = torch.transpose(pred[..., 2].repeat(label.shape[1], 1, 1), 0, 1)\n",
    "        h2 = torch.transpose(pred[..., 3].repeat(label.shape[1], 1, 1), 0, 1)\n",
    "        \n",
    "        x_loss = self.coef_coord * obj_mask * F.mse_loss(x1, x2, reduction='none')\n",
    "        y_loss = self.coef_coord * obj_mask * F.mse_loss(y1, y2, reduction='none')\n",
    "        w_loss = self.coef_coord * obj_mask * F.mse_loss(torch.sqrt(w1), torch.sqrt(w2), reduction='none')\n",
    "        h_loss = self.coef_coord * obj_mask * F.mse_loss(torch.sqrt(h1), torch.sqrt(h2), reduction='none')\n",
    "        \n",
    "        coord_loss = x_loss + y_loss + w_loss + h_loss\n",
    "        coord_loss = torch.sum(coord_loss)\n",
    "        if self.debug_level >= 4:\n",
    "            print('coord_loss.shape', coord_loss.shape)\n",
    "        \n",
    "        return coord_loss\n",
    "        \n",
    "        \n",
    "    def calc_iou(self, pred, label):\n",
    "        pred_xy = pred[:,0:2].clone()\n",
    "        pred_wh = pred[:,2:4].clone()\n",
    "        label_xy = label[:,0:2].clone()\n",
    "        label_wh = label[:,2:4].clone()\n",
    "        \n",
    "        c1 = torch.sum(torch.cartesian_prod(label_xy[:,0], pred_xy.mul(-1)[:,0]), 1).reshape(1, -1)\n",
    "        c2 = torch.sum(torch.cartesian_prod(label_xy[:,1], pred_xy.mul(-1)[:,1]), 1).reshape(1, -1)\n",
    "        inter_xy = torch.cat((c1, c2), dim = 0).t().view(label.shape[0], pred.shape[0], 2)\n",
    "        inter_xy = torch.abs(inter_xy)\n",
    "\n",
    "        c1 = torch.sum(torch.cartesian_prod(label_wh[:,0], pred_wh[:,0]), 1).reshape(1, -1)\n",
    "        c2 = torch.sum(torch.cartesian_prod(label_wh[:,1], pred_wh[:,1]), 1).reshape(1, -1)\n",
    "        inter_wh = torch.cat((c1, c2), dim = 0).t().view(label.shape[0], pred.shape[0], 2)\n",
    "        inter_wh = torch.add(torch.div(inter_wh, 2), inter_xy, alpha = -1)\n",
    "        inter_wh = F.relu(inter_wh)\n",
    "        \n",
    "        pred_area = torch.mul(pred_wh[:, 0], pred_wh[:, 1]).repeat(label.shape[0], 1)\n",
    "        label_area = torch.mul(label_wh[:, 0], label_wh[:, 1]).repeat(pred.shape[0], 1).t()\n",
    "        inter_area = torch.mul(inter_wh[:,:,0], inter_wh[:,:,1])\n",
    "        \n",
    "        output = inter_area / (pred_area + label_area - inter_area + self.iou_epsilon)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def calc_coord_loss(self, pred, label, responsible):\n",
    "        \n",
    "        resp_pred = torch.index_select(pred, 0, responsible)\n",
    "        if self.debug_level >= 4:\n",
    "            print('resp_pred : ', resp_pred)\n",
    "        resp_pred_xy = resp_pred[:, 0:2]\n",
    "        resp_pred_wh = resp_pred[:, 2:4]\n",
    "        resp_pred_wh = torch.sqrt(resp_pred_wh)\n",
    "        \n",
    "        label_xy = label[:, 0:2]\n",
    "        label_wh = label[:, 2:4]\n",
    "        label_wh = torch.sqrt(label_wh)\n",
    "        \n",
    "        output = torch.sum(torch.pow(label_xy - resp_pred_xy, 2), 1)\n",
    "        output += torch.sum(torch.pow(label_wh - resp_pred_wh, 2), 1)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def calc_confidence_loss(self, pred, iou, responsible):\n",
    "        conf = pred[:, 4].repeat(iou.shape[0], 1)\n",
    "        conf = torch.pow(conf - iou, 2)\n",
    "        \n",
    "        mean_conf = conf * self.coef_noobj\n",
    "        \n",
    "        for indx in range(responsible.shape[0]):\n",
    "            mean_conf[indx][responsible[indx]] += (1 - self.coef_noobj) * conf[indx][responsible[indx]]\n",
    "        \n",
    "        return conf\n",
    "    \n",
    "        \n",
    "    def calc_responsibile(self, iou):\n",
    "        \n",
    "        argmax = torch.argmax(iou, dim=1)\n",
    "        \n",
    "        return argmax\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create components\n",
    "learning_rate = 0.1\n",
    "loss_cache = []\n",
    "#lr_func = lambda epoch: learning_rate * (0.97 ** epoch) if epoch > 30 else 0.01\n",
    "lr_func = lambda epoch: learning_rate\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_func, last_epoch = -1)\n",
    "loss_func = YoloLoss(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(config, model, trainloader, loss_func, optimizer):\n",
    "    model.train()\n",
    "        \n",
    "    global learning_rate\n",
    "    global loss_cache\n",
    "    \n",
    "    avg_loss = []\n",
    "    \n",
    "    for idx, batches in enumerate(trainloader):\n",
    "        if config['debug_level'] >= 2:\n",
    "            print('index', idx)\n",
    "            \n",
    "        image = batches['image'].to(config['device'], dtype = config['dtype'])\n",
    "        labels = batches['label'].to(config['device'], dtype = config['dtype'])# / config['size'][0]\n",
    "        label_len = batches['label_len'].to(config['device'], dtype = torch.long)\n",
    "        if config['debug_level'] >= 3:\n",
    "            print('label shape : ', labels.shape)\n",
    "        \n",
    "        # forward\n",
    "        out1, out2, out3 = model(image)\n",
    "        \n",
    "        if config['debug_level'] >= 2:\n",
    "            print('out1.shape : ', out1.shape)\n",
    "            print('out1[0] : ', out1[0])\n",
    "            print('out2.shape : ', out2.shape)\n",
    "            print('out2[0] : ', out2[0])\n",
    "            print('out3.shape : ', out3.shape)\n",
    "            print('out3[0] : ', out3[0])\n",
    "            print('labels.shape : ', labels.shape)\n",
    "            print('labels[0] : ', labels[0])\n",
    "\n",
    "        # clear optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward\n",
    "        loss = loss_func(torch.cat((out1, out2, out3), 1), labels, label_len)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        avg_loss.append(loss.item())\n",
    "        \n",
    "        # cleanup\n",
    "        del image\n",
    "        del labels\n",
    "        del out1\n",
    "        del out2\n",
    "        del out3\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # update learning_rate\n",
    "    loss_cache.append(np.mean(avg_loss))\n",
    "        \n",
    "    if len(loss_cache) >= 10 and np.mean(loss_cache) < np.mean(loss_cache[-2:]) :\n",
    "        print('decrease learning rate from : ', learning_rate)\n",
    "        print('average of previous loss : ', np.mean(loss_cache))\n",
    "        print('length of previous loss : ', len(loss_cache))\n",
    "        learning_rate = learning_rate * 0.90\n",
    "        loss_cache = []\n",
    "        print('decrease learning rate to : ', learning_rate)\n",
    "    if len(loss_cache) > 20 :\n",
    "        loss_cache = loss_cache[15:]\n",
    "        \n",
    "    # print loss\n",
    "    if config['debug_level'] >= 1:\n",
    "        print('avg loss : ', np.mean(avg_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# single step\n",
    "with torch.autograd.set_detect_anomaly(False):\n",
    "    train_step(model_config, model, trainloader, loss_func, optimizer)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# value checking\n",
    "for epoch in range(0, 30):\n",
    "    print('epoch : ', epoch)\n",
    "    with torch.autograd.set_detect_anomaly(False):\n",
    "        trainset.shuffle()\n",
    "        train_step(model_config, model, trainloader, loss_func, optimizer)\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_config['debug_level'] = 0\n",
    "loss_func = YoloLoss(train_config)\n",
    "\n",
    "for epoch in range(30, 1200):\n",
    "    print('epoch : ', epoch)\n",
    "    trainset.shuffle()\n",
    "    train_step(model_config, model, trainloader, loss_func, optimizer)\n",
    "    scheduler.step()\n",
    "    \n",
    "    if epoch % 200 == 0 :\n",
    "        torch.save(model, './epoch_' + str(epoch) + '.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model, './epoch_2000.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
