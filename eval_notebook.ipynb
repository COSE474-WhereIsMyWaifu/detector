{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autograd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import json\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "from utils.dataset import DetectionFolder\n",
    "from utils.model import YoloV3, YoloLoss\n",
    "from utils.postprocess import PostProcessor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    "from collections import Counter\n",
    "\n",
    "import urllib\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config/config.json\", \"r\") as config_file:\n",
    "    main_config = json.load(config_file)\n",
    "\n",
    "try:\n",
    "    model_config = main_config['model']\n",
    "    test_config = main_config['test']\n",
    "except NameError:\n",
    "    assert False, ('Failed to load config file')\n",
    "except KeyError:\n",
    "    assert False, ('Failed to find key on config file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config['device'] = device\n",
    "model_config['dtype'] = dtype\n",
    "model_config['attrib_count'] = 5 + model_config['class_count']\n",
    "\n",
    "test_config['device'] = device\n",
    "test_config['dtype'] = dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./model/model_r_255.dat')\n",
    "model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_context = { }\n",
    "\n",
    "test_context['dataset'] = DetectionFolder(test_config['test_list'], test_config['test_image'], test_config['test_label'])\n",
    "test_context['dataloader'] = DataLoader(test_context['dataset'], batch_size = 1, num_workers = 1)\n",
    "\n",
    "test_context['post_conf_threshold'] = test_config['post_conf_threshold']\n",
    "test_context['post_iou_threshold'] = test_config['post_iou_threshold']\n",
    "test_context['acc_iou_threshold'] = test_config['acc_iou_threshold']\n",
    "\n",
    "test_context['video_dir'] = test_config['video_dir']\n",
    "test_context['font'] = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "\n",
    "test_context['debug_level'] = test_config['debug_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(bbox1, bbox2):\n",
    "    w1 = bbox1[2]\n",
    "    h1 = bbox1[3]\n",
    "    \n",
    "    w2 = bbox1[2]\n",
    "    h2 = bbox1[3]\n",
    "    \n",
    "    left1 = bbox1[0] - w1 / 2\n",
    "    left2 = bbox2[0] - w2 / 2\n",
    "    right1 = bbox1[0] + w1 / 2\n",
    "    right2 = bbox2[0] + w2 / 2\n",
    "    top1 = bbox1[1] + h1 / 2\n",
    "    top2 = bbox2[1] + h2 / 2\n",
    "    bottom1 = bbox1[1] - h1 / 2\n",
    "    bottom2 = bbox2[1] - h2 / 2\n",
    "    \n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    \n",
    "    w_intersect = min(right1, right2) - max(left1, left2)\n",
    "    h_intersect = min(top1, top2) - max(bottom1, bottom2)\n",
    "    area_intersect = h_intersect * w_intersect\n",
    "    \n",
    "    if w_intersect < 0 or h_intersect < 0:\n",
    "        return 0\n",
    "\n",
    "    iou_ = area_intersect / (area1 + area2 - area_intersect)\n",
    "    return iou_\n",
    "        \n",
    "def plot_pred(test_context, prediction, plot_options = ['ABOVE'], print_accuracy = False):\n",
    "        \n",
    "    if test_context['debug_level'] >= 1:\n",
    "        print('title : ', prediction['title'])\n",
    "        print('plot_options : ', plot_options)\n",
    "        \n",
    "    pred = prediction['pred']\n",
    "    image = prediction['image']\n",
    "    label = prediction['label']\n",
    "    label_len = prediction['label_len']\n",
    "    \n",
    "    postProcessor = PostProcessor()\n",
    "    \n",
    "    ax_indx = 0\n",
    "    _, ax = plt.subplots(1, len(plot_options), figsize=(8 * len(plot_options), 8))\n",
    "    \n",
    "    for plot_opt in plot_options:\n",
    "        # plot all boundingbox above threshold\n",
    "        if plot_opt is 'ABOVE':\n",
    "            pred_result = postProcessor.ABOVE(pred, test_context)\n",
    "            accuracy = None\n",
    "        elif plot_opt is 'NMS':\n",
    "            pred_result = postProcessor.NMS(pred, test_context)\n",
    "            if print_accuracy is True:\n",
    "                accuracy = postProcessor.calcAccuracyMap(label, label_len, pred_result, test_context)\n",
    "                print('NMS accuracy : ', accuracy)\n",
    "        elif plot_opt is 'CUSTOM1':\n",
    "            pred_result = postProcessor.CUSTOM1(pred, test_context)\n",
    "            if print_accuracy is True:\n",
    "                accuracy = postProcessor.calcAccuracyMap(label, label_len, pred_result, test_context)\n",
    "                print('CUSTOM1 accuracy : ', accuracy)\n",
    "        elif plot_opt is 'CUSTOM2':\n",
    "            pred_result = postProcessor.CUSTOM2(pred, test_context)\n",
    "            if print_accuracy is True:\n",
    "                accuracy = postProcessor.calcAccuracyMap(label, label_len, pred_result, test_context)\n",
    "                print('CUSTOM2 accuracy : ', accuracy)\n",
    "        else:\n",
    "            ax_indx = ax_indx + 1\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        if len(plot_options) > 1:\n",
    "            ax[ax_indx].imshow(image)\n",
    "        else:\n",
    "            ax.imshow(image)\n",
    "                \n",
    "        for bbox in pred_result:\n",
    "            color = '%02x'% int(255 * (bbox[4] - test_context['post_conf_threshold']) / (1 - test_context['post_conf_threshold']))\n",
    "            color = '#' + str(color) + str('00') + str('00')\n",
    "            \n",
    "            bounding = patches.Rectangle((bbox[0] - bbox[2] / 2, bbox[1] - bbox[3] / 2), bbox[2], bbox[3], \n",
    "                        linewidth=1, edgecolor=color, facecolor='none')\n",
    "                \n",
    "            if len(plot_options) > 1:\n",
    "                ax[ax_indx].add_patch(bounding)\n",
    "            else:\n",
    "                ax.add_patch(bounding)\n",
    "        ax_indx = ax_indx + 1\n",
    "    \n",
    "        \n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "        \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "def plot_save(test_context, target_name, prediction, size = (1920, 1080), plot_opt = 'CUSTOM2'):\n",
    "        \n",
    "    if test_context['debug_level'] >= 1:\n",
    "        print('title : ', prediction['title'])\n",
    "        \n",
    "    postProcessor = PostProcessor()\n",
    "    prediction = postProcessor.resize(from_size = (608, 608), to_size = size, prediction = prediction)\n",
    "    \n",
    "    pred = prediction['pred']\n",
    "    image = prediction['image']\n",
    "    label = prediction['label']\n",
    "    \n",
    "    if plot_opt is 'ABOVE':\n",
    "        pred_result = postProcessor.ABOVE(pred, test_context)\n",
    "    elif plot_opt is 'NMS':\n",
    "        pred_result = postProcessor.NMS(pred, test_context)\n",
    "    elif plot_opt is 'CUSTOM1':\n",
    "        pred_result = postProcessor.CUSTOM1(pred, test_context)\n",
    "    elif plot_opt is 'CUSTOM2':\n",
    "        pred_result = postProcessor.CUSTOM2(pred, test_context)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    imagepath = test_context['video_dir'] + target_name + '/' + prediction['title']\n",
    "    image = Image.open(imagepath)\n",
    "    image_pixels = image.load()\n",
    "    \n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    print(len(pred_result), 'boxes found')\n",
    "    for bbox in pred_result:\n",
    "        left = int(bbox[0] - bbox[2] / 2)\n",
    "        right = int(bbox[0] + bbox[2] / 2)\n",
    "        up = int(bbox[1] - bbox[3] / 2)\n",
    "        down = int(bbox[1] + bbox[3] / 2)\n",
    "        \n",
    "        if left >= 0 and up >= 0:\n",
    "            draw.text((left, up), str(bbox[4]),(255,0,0),font=test_context['font'])\n",
    "        elif left >= 0 and up < 0:\n",
    "            draw.text((left, down), str(bbox[4]),(255,0,0),font=test_context['font'])\n",
    "        elif left < 0 and up >= 0:\n",
    "            draw.text((right, up), str(bbox[4]),(255,0,0),font=test_context['font'])\n",
    "        else:\n",
    "            draw.text((right, up), str(bbox[4]),(255,0,0),font=test_context['font'])\n",
    "            \n",
    "            \n",
    "        draw.rectangle(xy=[left, up, right, down], outline=(255, 0, 0) )\n",
    "    output_dir = test_context['video_dir'] + 'o_' + target_name + '/'\n",
    "    image.save(output_dir + prediction['title'][:-3] + 'png')\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "        \n",
    "def test_all(test_context, test_config, plot_options = ['ABOVE', 'NMS', 'CUSTOM2']):\n",
    "    accs = Counter({})\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batches in enumerate(test_context['dataloader']):\n",
    "            image = batches['image'].to(test_config['device'], dtype = test_config['dtype'])\n",
    "            labels = batches['label'].to(test_config['device'], dtype = test_config['dtype'])\n",
    "            label_len = batches['label_len'].to(test_config['device'], dtype = torch.long)\n",
    "            \n",
    "            out1, out2, out3 = model(image)\n",
    "            pred = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "            output = {}\n",
    "            output['title'] = batches['title']\n",
    "            output['image'] = batches['image'].cpu().permute(0, 2, 3, 1).squeeze(0).numpy()\n",
    "            output['pred'] = pred.cpu().detach().squeeze(0).numpy()\n",
    "            output['label'] = batches['label'].cpu().squeeze(0).numpy()\n",
    "            output['label_len'] = batches['label_len'].cpu().squeeze(0).numpy()\n",
    "            \n",
    "            plot_pred(test_context, output, plot_options, print_accuracy = True)\n",
    "        \n",
    "            postProcessor = PostProcessor()\n",
    "            pred_result = postProcessor.CUSTOM2(output['pred'], test_context)\n",
    "            accuracy = postProcessor.calcAccuracyMap(output['label'], output['label_len'], pred_result, test_context)\n",
    "            accs = accs + Counter(accuracy)\n",
    "            \n",
    "            del image, labels, label_len\n",
    "            del out1, out2, out3, output\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        print('total : ', accs)\n",
    "        tp = accs['true positive']\n",
    "        fn = accs['false negative']\n",
    "        fp = accs['false positive'] + accs['duplicate']\n",
    "        print('accuracy : ', tp / (tp + fn + fp))\n",
    "\n",
    "def test_n(test_context, test_config, n = 1, plot_options = ['ABOVE', 'NMS', 'CUSTOM2']):\n",
    "    with torch.no_grad():\n",
    "        for idx, batches in enumerate(test_context['dataloader']):\n",
    "            image = batches['image'].to(test_config['device'], dtype = test_config['dtype'])\n",
    "            labels = batches['label'].to(test_config['device'], dtype = test_config['dtype'])\n",
    "            label_len = batches['label_len'].to(test_config['device'], dtype = torch.long)\n",
    "            \n",
    "            out1, out2, out3 = model(image)\n",
    "            pred = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "            output = {}\n",
    "            output['title'] = batches['title']\n",
    "            output['image'] = batches['image'].cpu().permute(0, 2, 3, 1).squeeze(0).numpy()\n",
    "            output['pred'] = pred.cpu().detach().squeeze(0).numpy()\n",
    "            output['label'] = batches['label'].cpu().squeeze(0).numpy()\n",
    "            output['label_len'] = batches['label_len'].cpu().squeeze(0).numpy()\n",
    "            \n",
    "            plot_pred(test_context, output, plot_options, print_accuracy = True)\n",
    "        \n",
    "            del image, labels, label_len\n",
    "            del out1, out2, out3, output\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            if idx + 1 >= n:\n",
    "                return\n",
    "            \n",
    "def test_url_image(test_context, test_config, url, crop = False, crop_size = (0, 0, 1920, 1080), \n",
    "                   plot_options = ['ABOVE', 'NMS', 'CUSTOM2']):\n",
    "    image = Image.open(urllib.request.urlopen(url))\n",
    "    if crop is True:\n",
    "        image = image.crop(crop_size)\n",
    "    image = np.array(image.resize((608, 608), Image.BILINEAR))[:, :, :3]\n",
    "    image = torch.from_numpy(image).unsqueeze(0).float() / 255\n",
    "    image = image.permute(0, 3, 1, 2)\n",
    "    \n",
    "    image = image.to(test_config['device'], dtype = test_config['dtype'])\n",
    "        \n",
    "    out1, out2, out3 = model(image)\n",
    "        \n",
    "    pred = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "    output = {}\n",
    "    output['title'] = url if len(url) < 80 else url[0:77] + '...' \n",
    "    output['image'] = image.permute(0, 2, 3, 1).cpu().squeeze(0).numpy()\n",
    "    output['pred'] = pred.cpu().detach().squeeze(0).numpy()\n",
    "    output['label'] = []\n",
    "    output['label_len'] = 0\n",
    "        \n",
    "    plot_pred(test_context, output, plot_options)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "def test_video(test_context, target_name, start = 0, size=(1920, 1080), plot_opt = 'CUSTOM2'):\n",
    "    file_list = os.listdir(test_context['video_dir'] + target_name + '/')\n",
    "    file_list = np.sort(file_list)\n",
    "    file_list = file_list[start:]\n",
    "    for image_name in file_list:\n",
    "        if fnmatch.fnmatch(image_name, '*.png') is False:\n",
    "            continue\n",
    "        print(image_name)\n",
    "        image = Image.open(test_context['video_dir'] + target_name + '/' + image_name)\n",
    "        image = np.array(image.resize((608, 608), Image.BILINEAR))[:, :, :3]\n",
    "        image = torch.from_numpy(image).unsqueeze(0).float() / 255\n",
    "        image = image.permute(0, 3, 1, 2)\n",
    "    \n",
    "        image = image.to(test_config['device'], dtype = test_config['dtype'])\n",
    "        \n",
    "        out1, out2, out3 = model(image)\n",
    "        \n",
    "        pred = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "        output = {}\n",
    "        output['title'] = image_name\n",
    "        output['image'] = image.permute(0, 2, 3, 1).cpu().squeeze(0).numpy()\n",
    "        output['pred'] = pred.cpu().detach().squeeze(0).numpy()\n",
    "        output['label'] = []\n",
    "        output['label_len'] = 0\n",
    "        \n",
    "        plot_save(test_context, target_name, output, size = size, plot_opt = plot_opt)\n",
    "            \n",
    "        del image\n",
    "        del out1, out2, out3\n",
    "        del output\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_all(test_context, test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with open(\"../data/detect/links/url_links.txt\", \"r\") as url_files:\n",
    "#    lines = url_files.readlines()\n",
    "#    for url in lines:\n",
    "#        try:\n",
    "#            test_context['debug_level'] = 1\n",
    "#            test_url_image(test_context, test_config, url)\n",
    "#        except urllib.error.HTTPError:\n",
    "#            print('http error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_video(test_context, 'toaru_majutsu_op', start = 0, size=(1280, 720), plot_opt = 'CUSTOM2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
