{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autograd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import json\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "from utils.dataset import LabeledDataset, VideoDataset\n",
    "from utils.model import YoloV3, YoloLoss\n",
    "from utils.postprocess import PostProcessor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    "from collections import Counter\n",
    "\n",
    "import urllib\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw \n",
    "\n",
    "from random import randint\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config/config.json\", \"r\") as config_file:\n",
    "    main_config = json.load(config_file)\n",
    "\n",
    "try:\n",
    "    model_config = main_config['model']\n",
    "    test_config = main_config['test']\n",
    "except NameError:\n",
    "    assert False, ('Failed to load config file')\n",
    "except KeyError:\n",
    "    assert False, ('Failed to find key on config file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config['device'] = device\n",
    "model_config['dtype'] = dtype\n",
    "model_config['attrib_count'] = 5 + model_config['class_count']\n",
    "\n",
    "test_config['device'] = device\n",
    "test_config['dtype'] = dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./model/run18/output_117.dat')\n",
    "model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_context = { }\n",
    "\n",
    "test_context['dataset'] = LabeledDataset(test_config['set']['index'], \n",
    "                                         test_config['set']['image_dir'], \n",
    "                                         test_config['set']['label_dir'])\n",
    "test_context['dataloader'] = DataLoader(test_context['dataset'], batch_size = 1, num_workers = 1)\n",
    "\n",
    "test_context['video_dir'] = test_config['video_dir']\n",
    "test_context['font'] = ImageFont.truetype(\"arial.ttf\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(bbox1, bbox2):\n",
    "    w1 = bbox1[2]\n",
    "    h1 = bbox1[3]\n",
    "    \n",
    "    w2 = bbox1[2]\n",
    "    h2 = bbox1[3]\n",
    "    \n",
    "    left1 = bbox1[0] - w1 / 2\n",
    "    left2 = bbox2[0] - w2 / 2\n",
    "    right1 = bbox1[0] + w1 / 2\n",
    "    right2 = bbox2[0] + w2 / 2\n",
    "    top1 = bbox1[1] + h1 / 2\n",
    "    top2 = bbox2[1] + h2 / 2\n",
    "    bottom1 = bbox1[1] - h1 / 2\n",
    "    bottom2 = bbox2[1] - h2 / 2\n",
    "    \n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    \n",
    "    w_intersect = min(right1, right2) - max(left1, left2)\n",
    "    h_intersect = min(top1, top2) - max(bottom1, bottom2)\n",
    "    area_intersect = h_intersect * w_intersect\n",
    "    \n",
    "    if w_intersect < 0 or h_intersect < 0:\n",
    "        return 0\n",
    "\n",
    "    iou_ = area_intersect / (area1 + area2 - area_intersect)\n",
    "    return iou_\n",
    "        \n",
    "def plot_pred(test_context, test_config, prediction, plot_options = ['ABOVE'], print_accuracy = False):\n",
    "        \n",
    "    print('title : ', prediction['title'])\n",
    "    print('plot_options : ', plot_options)\n",
    "        \n",
    "    pred = prediction['pred']\n",
    "    image = prediction['image']\n",
    "    label = prediction['label']\n",
    "    label_len = prediction['label_len']\n",
    "    \n",
    "    postProcessor = PostProcessor()\n",
    "    \n",
    "    ax_indx = 0\n",
    "    _, ax = plt.subplots(1, len(plot_options), figsize=(8 * len(plot_options), 8))\n",
    "    \n",
    "    for plot_opt in plot_options:\n",
    "        # plot all boundingbox above threshold\n",
    "        if plot_opt is 'ABOVE':\n",
    "            pred_result = postProcessor.ABOVE(pred, test_config['post'])\n",
    "            accuracy = None\n",
    "        elif plot_opt is 'NMS':\n",
    "            pred_result = postProcessor.NMS(pred, test_config['post'])\n",
    "            if print_accuracy is True:\n",
    "                accuracy = postProcessor.calcAccuracyMap(label, label_len, pred_result, test_config['post'])\n",
    "                print('NMS accuracy : ', accuracy)\n",
    "        elif plot_opt is 'CUSTOM1':\n",
    "            pred_result = postProcessor.CUSTOM1(pred, test_config['post'])\n",
    "            if print_accuracy is True:\n",
    "                accuracy = postProcessor.calcAccuracyMap(label, label_len, pred_result, test_config['post'])\n",
    "                print('CUSTOM1 accuracy : ', accuracy)\n",
    "        elif plot_opt is 'CUSTOM2':\n",
    "            pred_result = postProcessor.CUSTOM2(pred, test_config['post'])\n",
    "            if print_accuracy is True:\n",
    "                accuracy = postProcessor.calcAccuracyMap(label, label_len, pred_result, test_config['post'])\n",
    "                print('CUSTOM2 accuracy : ', accuracy)\n",
    "        else:\n",
    "            ax_indx = ax_indx + 1\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        if len(plot_options) > 1:\n",
    "            ax[ax_indx].imshow(image)\n",
    "        else:\n",
    "            ax.imshow(image)\n",
    "                \n",
    "        for bbox in pred_result:\n",
    "            #color = '%02x'% int(255 * (bbox[4] - test_context['post_conf_threshold']) / (1 - test_context['post_conf_threshold']))\n",
    "            #color = '#' + str(color) + str('00') + str('00')\n",
    "            color = '#FF0000'\n",
    "            \n",
    "            bounding = patches.Rectangle((bbox[0] - bbox[2] / 2, bbox[1] - bbox[3] / 2), bbox[2], bbox[3], \n",
    "                        linewidth=1, edgecolor=color, facecolor='none')\n",
    "                \n",
    "            if len(plot_options) > 1:\n",
    "                ax[ax_indx].add_patch(bounding)\n",
    "            else:\n",
    "                ax.add_patch(bounding)\n",
    "        ax_indx = ax_indx + 1\n",
    "    \n",
    "        \n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "        \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "        \n",
    "def test_all(test_context, test_config, plot_options = ['ABOVE', 'NMS', 'CUSTOM1']):\n",
    "    \n",
    "    postProcessor = PostProcessor()\n",
    "    \n",
    "    accs = Counter({})\n",
    "    custom2_count = 0\n",
    "    nms_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batches in enumerate(test_context['dataloader']):\n",
    "            image = batches['image'].to(test_config['device'], dtype = test_config['dtype'])\n",
    "            labels = batches['label'].to(test_config['device'], dtype = test_config['dtype'])\n",
    "            label_len = batches['label_len'].to(test_config['device'], dtype = torch.long)\n",
    "            \n",
    "            out1, out2, out3 = model(image)\n",
    "            pred = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "            output = {}\n",
    "            output['title'] = batches['title']\n",
    "            output['image'] = batches['image'].cpu().permute(0, 2, 3, 1).squeeze(0).numpy()\n",
    "            output['pred'] = pred.cpu().detach().squeeze(0).numpy()\n",
    "            output['label'] = batches['label'].cpu().squeeze(0).numpy()\n",
    "            output['label_len'] = batches['label_len'].cpu().squeeze(0).numpy()\n",
    "            \n",
    "            pred_result = postProcessor.CUSTOM1(output['pred'], test_config['post'])\n",
    "            accuracy = postProcessor.calcAccuracyMap(output['label'], output['label_len'], pred_result, test_config['post'])\n",
    "            accs = accs + Counter(accuracy)\n",
    "            \n",
    "            #plot_pred(test_context, output, plot_options, print_accuracy = True)\n",
    "            print(output['title'], ' : ', accuracy)\n",
    "            pred_custom2 = postProcessor.CUSTOM1(output['pred'], test_config['post'])\n",
    "            pred_NMS = postProcessor.NMS(output['pred'], test_config['post'])\n",
    "            \n",
    "            \n",
    "            # iou loss sum of custom2\n",
    "            iou_loss_sum_custom2 = 0\n",
    "            for p in pred_custom2:\n",
    "                max_indx = -1\n",
    "                max_iou = 0.01\n",
    "\n",
    "                for i in range(0, output['label_len']):\n",
    "                    iou_val = postProcessor.iou(p, output['label'][i])\n",
    "                    if max_iou < iou_val:\n",
    "                        max_iou = iou_val\n",
    "                        max_indx = i\n",
    "            \n",
    "                if max_indx is -1:\n",
    "                    iou_loss_sum_custom2 += 1\n",
    "                else:\n",
    "                    if max_iou > test_config['post']['acc_iou_threshold']:\n",
    "                        iou_loss_sum_custom2 = 1 - max_iou\n",
    "                    else:\n",
    "                        iou_loss_sum_custom2 += 1\n",
    "        \n",
    "            \n",
    "            # iou loss sum of nms\n",
    "            iou_loss_sum_nms = 0\n",
    "            for p in pred_NMS:\n",
    "                max_indx = -1\n",
    "                max_iou = 0.01\n",
    "\n",
    "                for i in range(0, output['label_len']):\n",
    "                    iou_val = postProcessor.iou(p, output['label'][i])\n",
    "                    if max_iou < iou_val:\n",
    "                        max_iou = iou_val\n",
    "                        max_indx = i\n",
    "            \n",
    "                if max_indx is -1:\n",
    "                    iou_loss_sum_nms += 1\n",
    "                else:\n",
    "                    if max_iou > test_config['post']['acc_iou_threshold']:\n",
    "                        iou_loss_sum_nms = 1 - max_iou\n",
    "                    else:\n",
    "                        iou_loss_sum_nms += 1\n",
    "            \n",
    "            if iou_loss_sum_nms > iou_loss_sum_custom2:\n",
    "                print('Custom2 : ', iou_loss_sum_custom2, ' vs ', iou_loss_sum_nms)\n",
    "                custom2_count += 1\n",
    "            elif iou_loss_sum_nms < iou_loss_sum_custom2:\n",
    "                print('NMS : ', iou_loss_sum_custom2, ' vs ', iou_loss_sum_nms)\n",
    "                nms_count += 1\n",
    "                \n",
    "            #if accuracy['false negative'] + accuracy['false positive'] + accuracy['duplicate'] != 0:\n",
    "            plot_pred(test_context, test_config, output, plot_options, print_accuracy = False)\n",
    "            \n",
    "            del image, labels, label_len\n",
    "            del out1, out2, out3, output\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        print('total : ', accs)\n",
    "        tp = accs['true positive']\n",
    "        fn = accs['false negative']\n",
    "        fp = accs['false positive'] + accs['duplicate']\n",
    "        print('accuracy : ', tp / (tp + fn + fp))\n",
    "        print('custom2 vs nms : ', custom2_count, ' ', nms_count)\n",
    "\n",
    "def test_n(test_context, test_config, n = 1, plot_options = ['ABOVE', 'NMS', 'CUSTOM2']):\n",
    "    with torch.no_grad():\n",
    "        for idx, batches in enumerate(test_context['dataloader']):\n",
    "            image = batches['image'].to(test_config['device'], dtype = test_config['dtype'])\n",
    "            labels = batches['label'].to(test_config['device'], dtype = test_config['dtype'])\n",
    "            label_len = batches['label_len'].to(test_config['device'], dtype = torch.long)\n",
    "            \n",
    "            out1, out2, out3 = model(image)\n",
    "            pred = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "            output = {}\n",
    "            output['title'] = batches['title']\n",
    "            output['image'] = batches['image'].cpu().permute(0, 2, 3, 1).squeeze(0).numpy()\n",
    "            output['pred'] = pred.cpu().detach().squeeze(0).numpy()\n",
    "            output['label'] = batches['label'].cpu().squeeze(0).numpy()\n",
    "            output['label_len'] = batches['label_len'].cpu().squeeze(0).numpy()\n",
    "            \n",
    "            plot_pred(test_context, output, plot_options, print_accuracy = True)\n",
    "        \n",
    "            del image, labels, label_len\n",
    "            del out1, out2, out3, output\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            if idx + 1 >= n:\n",
    "                return\n",
    "            \n",
    "def test_url_image(test_context, test_config, url, crop = False, crop_size = (0, 0, 1920, 1080), \n",
    "                   plot_options = ['ABOVE', 'NMS', 'CUSTOM2']):\n",
    "    image = Image.open(urllib.request.urlopen(url))\n",
    "    if crop is True:\n",
    "        image = image.crop(crop_size)\n",
    "    image = np.array(image.resize((608, 608), Image.BILINEAR))[:, :, :3]\n",
    "    image = torch.from_numpy(image).unsqueeze(0).float() / 255\n",
    "    image = image.permute(0, 3, 1, 2)\n",
    "    \n",
    "    image = image.to(test_config['device'], dtype = test_config['dtype'])\n",
    "        \n",
    "    out1, out2, out3 = model(image)\n",
    "        \n",
    "    pred = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "    output = {}\n",
    "    output['title'] = url if len(url) < 80 else url[0:77] + '...' \n",
    "    output['image'] = image.permute(0, 2, 3, 1).cpu().squeeze(0).numpy()\n",
    "    output['pred'] = pred.cpu().detach().squeeze(0).numpy()\n",
    "    output['label'] = []\n",
    "    output['label_len'] = 0\n",
    "        \n",
    "    plot_pred(test_context, output, plot_options)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_all(test_context, test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kernel(conv_layer, group_thres = 2):\n",
    "    if type(conv_layer) is not torch.nn.modules.conv.Conv2d:\n",
    "        print('layer not Conv2d')\n",
    "        return\n",
    "    kernels = conv_layer.weight.data.detach().cpu()\n",
    "    cnt = kernels.shape[0]\n",
    "    \n",
    "    similar_group = []\n",
    "    for i in range(0, cnt):\n",
    "        for j in range(i, cnt):\n",
    "            if i == j:\n",
    "                continue\n",
    "                \n",
    "            kernel_i = kernels[i].numpy().astype(np.float)\n",
    "            max_num = np.max(np.abs(kernel_i))\n",
    "            kernel_i = kernel_i / max_num\n",
    "            kernel_j = kernels[j].numpy().astype(np.float)\n",
    "            max_num = np.max(np.abs(kernel_j))\n",
    "            kernel_j = kernel_j / max_num\n",
    "                \n",
    "            diff = kernel_i - kernel_j\n",
    "            diff = np.abs(diff)\n",
    "            diff = np.sum(diff)\n",
    "            \n",
    "            if diff < group_thres:\n",
    "                new_group = True\n",
    "                for g in similar_group:\n",
    "                    if i in g:\n",
    "                        new_group = False\n",
    "                        g.add(j)\n",
    "                if new_group:\n",
    "                    similar_group.append(set([i, j]))\n",
    "    print(similar_group)\n",
    "    \n",
    "    group_color = []\n",
    "    for i in range(0, len(similar_group)):\n",
    "        r = '%02X' % randint(0, 255)\n",
    "        g = '%02X' % randint(0, 255)\n",
    "        b = '%02X' % randint(0, 255)\n",
    "        group_color.append('#' + str(r) + str(g) + str(b))\n",
    "    print(group_color)\n",
    "                \n",
    "    fig, ax = plt.subplots(cnt // 8, 8, figsize=(16, 16))\n",
    "    for i in range(0, cnt // 8):\n",
    "        for j in range(0, 8):\n",
    "            kernel = kernels[i * 8 + j].numpy().astype(np.float)\n",
    "            max_num = np.max(np.abs(kernel))\n",
    "            kernel = kernel / max_num\n",
    "            kernel = (kernel + 1)/ 2\n",
    "            \n",
    "            ax[i, j].imshow(kernel)\n",
    "            \n",
    "    for g in range(0, len(similar_group)):\n",
    "        for i in similar_group[g]:\n",
    "            ax[i // 8, i % 8].spines['left'].set_color(group_color[g])\n",
    "            ax[i // 8, i % 8].spines['right'].set_color(group_color[g])\n",
    "            ax[i // 8, i % 8].spines['bottom'].set_color(group_color[g])\n",
    "            \n",
    "            ax[i // 8, i % 8].tick_params(axis='x', colors = group_color[g])\n",
    "            ax[i // 8, i % 8].tick_params(axis='y', colors = group_color[g])\n",
    "            \n",
    "    for i in range(0, cnt):\n",
    "        kernel = kernels[i].numpy().astype(np.float)\n",
    "        max_num = np.max(np.abs(kernel))\n",
    "        \n",
    "        if max_num < 0.3 :\n",
    "            ax[i // 8, i % 8].spines['top'].set_color('red')\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_kernel(model.darknet.baseline[0].body[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with open(\"../data/detect/links/url_links.txt\", \"r\") as url_files:\n",
    "#    lines = url_files.readlines()\n",
    "#    for url in lines:\n",
    "#        try:\n",
    "#            test_context['debug_level'] = 1\n",
    "#            test_url_image(test_context, test_config, url)\n",
    "#        except urllib.error.HTTPError:\n",
    "#            print('http error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_video(test_context, 'toaru_majutsu_op', start = 0, size=(1280, 720), plot_opt = 'CUSTOM2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_video2(context, config, target_name, size=(1920, 1080), splits = (1, 1), batch_multiplier = 1, post_opt = 'CUSTOM1'):\n",
    "    split_count = splits[0] * splits[1]\n",
    "    batch_size = batch_multiplier * split_count\n",
    "    \n",
    "    image_dir = test_context['video_dir'] + target_name + '/'\n",
    "    dataset = VideoDataset(image_dir, splits = splits, from_size = size, to_size = (608, 608))\n",
    "    loader = DataLoader(dataset, batch_size = batch_size, num_workers = 1)\n",
    "    postprocess = PostProcessor()\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batches in enumerate(loader):\n",
    "            image = batches['image'].to(config['device'], dtype = config['dtype'])\n",
    "            \n",
    "            out1, out2, out3 = model(image)\n",
    "            pred = torch.cat((out1, out2, out3), 1)\n",
    "            \n",
    "            for i in range(0, batches['image'].shape[0] // split_count):\n",
    "                # processing image\n",
    "                print(batches['title'][i * split_count])\n",
    "                \n",
    "                # 1. recover prediction coordinate\n",
    "                for j in range(0, split_count):\n",
    "                    crop_size = batches['crop_size'][i * split_count + j]\n",
    "                    crop_bbox = batches['crop_bbox'][i * split_count + j]\n",
    "    \n",
    "                    split_ratio = float(max(crop_size[0], crop_size[1])) / 608\n",
    "                    \n",
    "                    crop_mult = torch.as_tensor([split_ratio, \n",
    "                                                 split_ratio, \n",
    "                                                 split_ratio, \n",
    "                                                 split_ratio]).to(config['device'], dtype = config['dtype'])\n",
    "                    crop_add = torch.as_tensor([crop_bbox[0], \n",
    "                                                crop_bbox[1], \n",
    "                                                0, \n",
    "                                                0]).to(config['device'], dtype = config['dtype'])\n",
    "                    \n",
    "                    pred[i * split_count + j][:, :4].mul_(crop_mult).add_(crop_add)\n",
    "                \n",
    "                # 2. concat splits\n",
    "                pred_result = torch.cat(tuple(pred[i * split_count : (i + 1) * split_count]), dim = 0).cpu().detach()\n",
    "                pred_result = np.copy(pred_result[np.where(pred_result[:, 4] > context['post_conf_threshold'])])\n",
    "                \n",
    "                # 3. run CUSTOM1\n",
    "                pred_result = postprocess.CUSTOM1(pred_result, context)\n",
    "                print(len(pred_result), 'boxes found')\n",
    "            \n",
    "                \n",
    "                # 4. to pillow\n",
    "                image_to_save = batches['image_og'][i * split_count].cpu().numpy()\n",
    "                image_to_save = Image.fromarray(image_to_save.astype('uint8'), 'RGB')\n",
    "            \n",
    "                # 5. draw image\n",
    "                draw = ImageDraw.Draw(image_to_save)\n",
    "                for bbox in pred_result:\n",
    "                    left = int(bbox[0] - bbox[2] / 2)\n",
    "                    right = int(bbox[0] + bbox[2] / 2)\n",
    "                    up = int(bbox[1] - bbox[3] / 2)\n",
    "                    down = int(bbox[1] + bbox[3] / 2)\n",
    "        \n",
    "                    draw.text((left, down), str(bbox[4]),(255,0,0),font=test_context['font'])\n",
    "                    draw.rectangle(xy=[left, up, right, down], outline=(255, 0, 0) )\n",
    "            \n",
    "                # 6_1. save image\n",
    "                output_dir = test_context['video_dir'] + 'o_' + target_name + '/'\n",
    "                image_to_save.save(output_dir + batches['title'][i * split_count][:-3] + 'png')\n",
    "                \n",
    "                # 6_2. show image\n",
    "                #_, ax = plt.subplots(figsize=(16, 9))\n",
    "                #ax.imshow(np.array(image_to_save))\n",
    "                #plt.show()\n",
    "            \n",
    "            del image, batches\n",
    "            del out1, out2, out3, pred\n",
    "            del pred_result\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now().time()\n",
    "print('start time : ', start_time)\n",
    "#test_video2(test_context, test_config, 'imas_ready', size=(1920, 1080), splits = (2, 1), batch_multiplier = 1, post_opt = 'CUSTOM1')\n",
    "end_time = datetime.datetime.now().time()\n",
    "\n",
    "print('done')\n",
    "print('start time : ', start_time)\n",
    "print('end time : ', end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
